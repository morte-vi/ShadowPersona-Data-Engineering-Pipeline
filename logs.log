2025-06-18 01:52:43,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:52:43,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:52:43,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:52:43,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:54:11,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:54:11,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:54:11,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:54:11,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:54:40,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:54:40,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:54:40,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:54:40,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:55:46,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:55:46,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:55:46,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:55:46,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:55:47,297:INFO:PyCaret ClassificationExperiment
2025-06-18 01:55:47,297:INFO:Logging name: clf-default-name
2025-06-18 01:55:47,297:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-18 01:55:47,297:INFO:version 3.3.2
2025-06-18 01:55:47,297:INFO:Initializing setup()
2025-06-18 01:55:47,297:INFO:self.USI: bc31
2025-06-18 01:55:47,297:INFO:self._variable_keys: {'gpu_n_jobs_param', 'gpu_param', 'logging_param', 'y_test', 'y', 'pipeline', 'y_train', 'exp_name_log', 'X', 'fold_generator', 'fold_shuffle_param', 'memory', 'idx', 'seed', 'X_test', 'n_jobs_param', 'data', 'USI', 'target_param', 'is_multiclass', '_ml_usecase', '_available_plots', 'fix_imbalance', 'log_plots_param', 'X_train', 'exp_id', 'html_param', 'fold_groups_param'}
2025-06-18 01:55:47,297:INFO:Checking environment
2025-06-18 01:55:47,297:INFO:python_version: 3.11.9
2025-06-18 01:55:47,297:INFO:python_build: ('main', 'Jun 15 2025 22:35:33')
2025-06-18 01:55:47,297:INFO:machine: arm64
2025-06-18 01:55:47,322:INFO:platform: macOS-15.5-arm64-arm-64bit
2025-06-18 01:55:47,323:INFO:Memory: svmem(total=8589934592, available=2015330304, percent=76.5, used=3523985408, free=71827456, active=1956151296, inactive=1832665088, wired=1567834112)
2025-06-18 01:55:47,323:INFO:Physical Core: 8
2025-06-18 01:55:47,323:INFO:Logical Core: 8
2025-06-18 01:55:47,323:INFO:Checking libraries
2025-06-18 01:55:47,323:INFO:System:
2025-06-18 01:55:47,323:INFO:    python: 3.11.9 (main, Jun 15 2025, 22:35:33) [Clang 17.0.0 (clang-1700.0.13.5)]
2025-06-18 01:55:47,323:INFO:executable: /Users/om/Documents/Github-Projects/shadowpersona/venv/bin/python
2025-06-18 01:55:47,323:INFO:   machine: macOS-15.5-arm64-arm-64bit
2025-06-18 01:55:47,323:INFO:PyCaret required dependencies:
2025-06-18 01:56:47,259:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:56:47,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:56:47,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:56:47,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-18 01:56:48,388:INFO:PyCaret ClassificationExperiment
2025-06-18 01:56:48,388:INFO:Logging name: clf-default-name
2025-06-18 01:56:48,388:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-18 01:56:48,388:INFO:version 3.3.2
2025-06-18 01:56:48,388:INFO:Initializing setup()
2025-06-18 01:56:48,388:INFO:self.USI: 9ba6
2025-06-18 01:56:48,388:INFO:self._variable_keys: {'_available_plots', 'y_train', 'pipeline', 'y', 'X_train', 'fix_imbalance', 'gpu_n_jobs_param', 'log_plots_param', 'idx', 'seed', 'data', 'html_param', 'fold_generator', 'gpu_param', 'exp_id', 'n_jobs_param', 'target_param', 'USI', 'X_test', 'memory', 'exp_name_log', 'logging_param', 'fold_shuffle_param', 'fold_groups_param', '_ml_usecase', 'X', 'is_multiclass', 'y_test'}
2025-06-18 01:56:48,388:INFO:Checking environment
2025-06-18 01:56:48,388:INFO:python_version: 3.11.9
2025-06-18 01:56:48,388:INFO:python_build: ('main', 'Jun 15 2025 22:35:33')
2025-06-18 01:56:48,388:INFO:machine: arm64
2025-06-18 01:56:48,407:INFO:platform: macOS-15.5-arm64-arm-64bit
2025-06-18 01:56:48,408:INFO:Memory: svmem(total=8589934592, available=2035007488, percent=76.3, used=3550822400, free=69156864, active=1976369152, inactive=1843314688, wired=1574453248)
2025-06-18 01:56:48,408:INFO:Physical Core: 8
2025-06-18 01:56:48,408:INFO:Logical Core: 8
2025-06-18 01:56:48,408:INFO:Checking libraries
2025-06-18 01:56:48,408:INFO:System:
2025-06-18 01:56:48,408:INFO:    python: 3.11.9 (main, Jun 15 2025, 22:35:33) [Clang 17.0.0 (clang-1700.0.13.5)]
2025-06-18 01:56:48,408:INFO:executable: /Users/om/Documents/Github-Projects/shadowpersona/venv/bin/python
2025-06-18 01:56:48,408:INFO:   machine: macOS-15.5-arm64-arm-64bit
2025-06-18 01:56:48,408:INFO:PyCaret required dependencies:
2025-06-18 01:56:48,810:INFO:                 pip: 24.0
2025-06-18 01:56:48,810:INFO:          setuptools: 65.5.0
2025-06-18 01:56:48,810:INFO:             pycaret: 3.3.2
2025-06-18 01:56:48,810:INFO:             IPython: 9.3.0
2025-06-18 01:56:48,810:INFO:          ipywidgets: 8.1.7
2025-06-18 01:56:48,810:INFO:                tqdm: 4.67.1
2025-06-18 01:56:48,810:INFO:               numpy: 1.26.4
2025-06-18 01:56:48,811:INFO:              pandas: 2.1.4
2025-06-18 01:56:48,811:INFO:              jinja2: 3.1.6
2025-06-18 01:56:48,811:INFO:               scipy: 1.11.4
2025-06-18 01:56:48,811:INFO:              joblib: 1.3.2
2025-06-18 01:56:48,811:INFO:             sklearn: 1.4.2
2025-06-18 01:56:48,811:INFO:                pyod: 2.0.5
2025-06-18 01:56:48,811:INFO:            imblearn: 0.13.0
2025-06-18 01:56:48,811:INFO:   category_encoders: 2.7.0
2025-06-18 01:56:48,811:INFO:            lightgbm: 4.6.0
2025-06-18 01:56:48,811:INFO:               numba: 0.61.2
2025-06-18 01:56:48,811:INFO:            requests: 2.32.4
2025-06-18 01:56:48,811:INFO:          matplotlib: 3.7.5
2025-06-18 01:56:48,811:INFO:          scikitplot: 0.3.7
2025-06-18 01:56:48,811:INFO:         yellowbrick: 1.5
2025-06-18 01:56:48,811:INFO:              plotly: 5.24.1
2025-06-18 01:56:48,811:INFO:    plotly-resampler: Not installed
2025-06-18 01:56:48,811:INFO:             kaleido: 0.2.1
2025-06-18 01:56:48,811:INFO:           schemdraw: 0.15
2025-06-18 01:56:48,811:INFO:         statsmodels: 0.14.4
2025-06-18 01:56:48,811:INFO:              sktime: 0.26.0
2025-06-18 01:56:48,811:INFO:               tbats: 1.1.3
2025-06-18 01:56:48,811:INFO:            pmdarima: 2.0.4
2025-06-18 01:56:48,811:INFO:              psutil: 7.0.0
2025-06-18 01:56:48,811:INFO:          markupsafe: 3.0.2
2025-06-18 01:56:48,811:INFO:             pickle5: Not installed
2025-06-18 01:56:48,811:INFO:         cloudpickle: 3.1.1
2025-06-18 01:56:48,811:INFO:         deprecation: 2.1.0
2025-06-18 01:56:48,811:INFO:              xxhash: 3.5.0
2025-06-18 01:56:48,811:INFO:           wurlitzer: 3.1.1
2025-06-18 01:56:48,811:INFO:PyCaret optional dependencies:
2025-06-18 01:56:48,819:INFO:                shap: Not installed
2025-06-18 01:56:48,819:INFO:           interpret: Not installed
2025-06-18 01:56:48,819:INFO:                umap: Not installed
2025-06-18 01:56:48,819:INFO:     ydata_profiling: Not installed
2025-06-18 01:56:48,819:INFO:  explainerdashboard: Not installed
2025-06-18 01:56:48,819:INFO:             autoviz: Not installed
2025-06-18 01:56:48,819:INFO:           fairlearn: Not installed
2025-06-18 01:56:48,819:INFO:          deepchecks: Not installed
2025-06-18 01:56:48,819:INFO:             xgboost: Not installed
2025-06-18 01:56:48,819:INFO:            catboost: Not installed
2025-06-18 01:56:48,819:INFO:              kmodes: Not installed
2025-06-18 01:56:48,819:INFO:             mlxtend: Not installed
2025-06-18 01:56:48,819:INFO:       statsforecast: Not installed
2025-06-18 01:56:48,820:INFO:        tune_sklearn: Not installed
2025-06-18 01:56:48,820:INFO:                 ray: Not installed
2025-06-18 01:56:48,820:INFO:            hyperopt: Not installed
2025-06-18 01:56:48,820:INFO:              optuna: Not installed
2025-06-18 01:56:48,820:INFO:               skopt: Not installed
2025-06-18 01:56:48,820:INFO:              mlflow: Not installed
2025-06-18 01:56:48,820:INFO:              gradio: Not installed
2025-06-18 01:56:48,820:INFO:             fastapi: Not installed
2025-06-18 01:56:48,820:INFO:             uvicorn: Not installed
2025-06-18 01:56:48,820:INFO:              m2cgen: Not installed
2025-06-18 01:56:48,820:INFO:           evidently: Not installed
2025-06-18 01:56:48,820:INFO:               fugue: Not installed
2025-06-18 01:56:48,820:INFO:           streamlit: Not installed
2025-06-18 01:56:48,820:INFO:             prophet: Not installed
2025-06-18 01:56:48,820:INFO:None
2025-06-18 01:56:48,820:INFO:Set up data.
2025-06-18 01:56:49,204:INFO:Set up folding strategy.
2025-06-18 01:56:49,204:INFO:Set up train/test split.
2025-06-18 01:56:49,671:INFO:Set up index.
2025-06-18 01:56:49,673:INFO:Assigning column types.
2025-06-18 01:56:49,690:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-18 01:56:49,720:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-18 01:56:49,722:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-18 01:56:49,745:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:49,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:49,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-18 01:56:49,776:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-18 01:56:49,794:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:49,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:49,795:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-18 01:56:49,826:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-18 01:56:49,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:49,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:49,876:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-18 01:56:49,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:49,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:49,895:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-18 01:56:49,944:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:49,944:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:49,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:49,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:49,997:INFO:Preparing preprocessing pipeline...
2025-06-18 01:56:50,001:INFO:Set up label encoding.
2025-06-18 01:56:50,001:INFO:Set up simple imputation.
2025-06-18 01:56:50,019:INFO:Set up encoding of categorical features.
2025-06-18 01:56:52,979:INFO:Finished creating preprocessing pipeline.
2025-06-18 01:56:52,984:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/_l/2c1bx3jx7190xc9fkzzb0fkm0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['session_time', 'rage_clicks',
                                             'doomscroll_length',
                                             'feed_bias_score',
                                             'notif_response_ti...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['user_id', 'notification_time'],
                                    transformer=TargetEncoder(cols=['user_id',
                                                                    'notification_time'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-06-18 01:56:52,984:INFO:Creating final display dataframe.
2025-06-18 01:56:56,157:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                 42
1                        Target                                    predicted_trait
2                   Target type                                         Multiclass
3                Target mapping  anxious: 0, emotionally fragile: 1, habitual: ...
4           Original data shape                                       (222222, 14)
5        Transformed data shape                                       (222222, 37)
6   Transformed train set shape                                       (155555, 37)
7    Transformed test set shape                                        (66667, 37)
8              Numeric features                                                  6
9          Categorical features                                                  7
10                   Preprocess                                               True
11              Imputation type                                             simple
12           Numeric imputation                                               mean
13       Categorical imputation                                               mode
14     Maximum one-hot encoding                                                 25
15              Encoding method                                               None
16               Fold Generator                                    StratifiedKFold
17                  Fold Number                                                 10
18                     CPU Jobs                                                 -1
19                      Use GPU                                              False
20               Log Experiment                                              False
21              Experiment Name                                   clf-default-name
22                          USI                                               9ba6
2025-06-18 01:56:56,209:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:56,209:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:56,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:56,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-18 01:56:56,259:INFO:setup() successfully completed in 7.87s...............
2025-06-18 01:56:56,259:INFO:Initializing compare_models()
2025-06-18 01:56:56,259:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x102534e10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x102534e10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-06-18 01:56:56,260:INFO:Checking exceptions
2025-06-18 01:56:56,278:INFO:Preparing display monitor
2025-06-18 01:56:56,691:INFO:Initializing Logistic Regression
2025-06-18 01:56:56,691:INFO:Total runtime is 3.0835469563802084e-06 minutes
2025-06-18 01:56:56,691:INFO:SubProcess create_model() called ==================================
2025-06-18 01:56:56,691:INFO:Initializing create_model()
2025-06-18 01:56:56,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x102534e10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e762710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-18 01:56:56,691:INFO:Checking exceptions
2025-06-18 01:56:56,691:INFO:Importing libraries
2025-06-18 01:56:56,691:INFO:Copying training dataset
2025-06-18 01:56:56,731:INFO:Defining folds
2025-06-18 01:56:56,731:INFO:Declaring metric variables
2025-06-18 01:56:56,731:INFO:Importing untrained model
2025-06-18 01:56:56,731:INFO:Logistic Regression Imported successfully
2025-06-18 01:56:56,732:INFO:Starting cross validation
2025-06-18 01:56:56,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-18 01:58:42,296:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-18 01:58:42,865:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 01:58:42,966:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:43,248:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:43,376:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-18 01:58:43,448:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:43,817:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 01:58:43,888:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:44,155:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-18 01:58:44,158:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:44,376:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:44,562:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-18 01:58:44,612:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 01:58:44,637:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-18 01:58:44,700:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:44,738:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-18 01:58:44,872:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:44,994:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 01:58:45,014:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 01:58:45,026:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 01:58:45,063:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:45,082:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:45,125:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 01:58:45,154:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-18 01:58:45,226:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:45,233:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:45,274:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:45,276:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:45,417:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:45,460:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:45,465:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:45,558:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 01:58:45,577:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 01:58:45,612:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-18 01:58:45,622:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:45,642:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:45,800:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:45,938:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:45,981:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 01:58:46,047:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:46,190:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:58:46,260:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 01:58:46,309:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:59:23,098:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-18 01:59:23,286:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 01:59:23,335:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:59:23,435:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:59:23,529:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:59:23,609:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-18 01:59:23,746:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 01:59:23,786:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:59:23,868:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:59:23,948:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 01:59:24,175:INFO:Calculating mean and std
2025-06-18 01:59:24,179:INFO:Creating metrics dataframe
2025-06-18 01:59:24,184:INFO:Uploading results into container
2025-06-18 01:59:24,184:INFO:Uploading model into container now
2025-06-18 01:59:24,185:INFO:_master_model_container: 1
2025-06-18 01:59:24,185:INFO:_display_container: 2
2025-06-18 01:59:24,186:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-18 01:59:24,186:INFO:create_model() successfully completed......................................
2025-06-18 01:59:24,313:INFO:SubProcess create_model() end ==================================
2025-06-18 01:59:24,313:INFO:Creating metrics dataframe
2025-06-18 01:59:24,314:INFO:Initializing K Neighbors Classifier
2025-06-18 01:59:24,314:INFO:Total runtime is 2.460391930739085 minutes
2025-06-18 01:59:24,314:INFO:SubProcess create_model() called ==================================
2025-06-18 01:59:24,314:INFO:Initializing create_model()
2025-06-18 01:59:24,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x102534e10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e762710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-18 01:59:24,315:INFO:Checking exceptions
2025-06-18 01:59:24,315:INFO:Importing libraries
2025-06-18 01:59:24,316:INFO:Copying training dataset
2025-06-18 01:59:24,363:INFO:Defining folds
2025-06-18 01:59:24,363:INFO:Declaring metric variables
2025-06-18 01:59:24,363:INFO:Importing untrained model
2025-06-18 01:59:24,363:INFO:K Neighbors Classifier Imported successfully
2025-06-18 01:59:24,364:INFO:Starting cross validation
2025-06-18 01:59:24,366:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-18 02:00:31,284:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:31,477:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:31,737:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:31,939:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:32,156:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:32,353:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:32,376:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:32,567:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:32,619:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:32,743:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:32,820:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:32,923:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:33,062:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:33,175:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:33,354:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:33,449:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:33,574:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:33,675:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:33,908:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:33,926:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:34,019:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:34,037:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:34,156:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:34,185:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:58,261:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:58,341:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:58,421:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:58,531:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:58,612:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:58,692:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:00:58,910:INFO:Calculating mean and std
2025-06-18 02:00:58,911:INFO:Creating metrics dataframe
2025-06-18 02:00:58,916:INFO:Uploading results into container
2025-06-18 02:00:58,917:INFO:Uploading model into container now
2025-06-18 02:00:58,918:INFO:_master_model_container: 2
2025-06-18 02:00:58,918:INFO:_display_container: 2
2025-06-18 02:00:58,919:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-18 02:00:58,919:INFO:create_model() successfully completed......................................
2025-06-18 02:00:59,027:INFO:SubProcess create_model() end ==================================
2025-06-18 02:00:59,027:INFO:Creating metrics dataframe
2025-06-18 02:00:59,029:INFO:Initializing Naive Bayes
2025-06-18 02:00:59,029:INFO:Total runtime is 4.038969031969707 minutes
2025-06-18 02:00:59,029:INFO:SubProcess create_model() called ==================================
2025-06-18 02:00:59,029:INFO:Initializing create_model()
2025-06-18 02:00:59,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x102534e10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e762710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-18 02:00:59,029:INFO:Checking exceptions
2025-06-18 02:00:59,029:INFO:Importing libraries
2025-06-18 02:00:59,030:INFO:Copying training dataset
2025-06-18 02:00:59,078:INFO:Defining folds
2025-06-18 02:00:59,079:INFO:Declaring metric variables
2025-06-18 02:00:59,079:INFO:Importing untrained model
2025-06-18 02:00:59,079:INFO:Naive Bayes Imported successfully
2025-06-18 02:00:59,079:INFO:Starting cross validation
2025-06-18 02:00:59,081:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-18 02:01:07,367:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:07,644:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:07,762:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:07,825:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:08,659:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:08,672:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:08,821:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:08,860:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:08,988:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:09,048:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:09,075:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:09,098:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:09,154:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:09,206:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:09,223:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:09,249:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:09,300:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:09,305:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:09,345:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:09,383:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:09,573:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:09,766:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:09,778:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:09,856:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:09,886:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:09,925:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:09,953:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:10,017:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:10,033:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:10,092:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:10,110:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:10,146:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:12,951:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:13,097:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:13,175:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:13,223:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:13,348:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:13,440:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:13,495:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:13,534:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:13,763:INFO:Calculating mean and std
2025-06-18 02:01:13,765:INFO:Creating metrics dataframe
2025-06-18 02:01:13,770:INFO:Uploading results into container
2025-06-18 02:01:13,770:INFO:Uploading model into container now
2025-06-18 02:01:13,771:INFO:_master_model_container: 3
2025-06-18 02:01:13,771:INFO:_display_container: 2
2025-06-18 02:01:13,771:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-18 02:01:13,771:INFO:create_model() successfully completed......................................
2025-06-18 02:01:13,869:INFO:SubProcess create_model() end ==================================
2025-06-18 02:01:13,869:INFO:Creating metrics dataframe
2025-06-18 02:01:13,871:INFO:Initializing Decision Tree Classifier
2025-06-18 02:01:13,871:INFO:Total runtime is 4.286332066853841 minutes
2025-06-18 02:01:13,871:INFO:SubProcess create_model() called ==================================
2025-06-18 02:01:13,871:INFO:Initializing create_model()
2025-06-18 02:01:13,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x102534e10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e762710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-18 02:01:13,871:INFO:Checking exceptions
2025-06-18 02:01:13,871:INFO:Importing libraries
2025-06-18 02:01:13,871:INFO:Copying training dataset
2025-06-18 02:01:13,919:INFO:Defining folds
2025-06-18 02:01:13,919:INFO:Declaring metric variables
2025-06-18 02:01:13,919:INFO:Importing untrained model
2025-06-18 02:01:13,919:INFO:Decision Tree Classifier Imported successfully
2025-06-18 02:01:13,919:INFO:Starting cross validation
2025-06-18 02:01:13,922:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-18 02:01:21,666:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:21,822:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:21,915:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:22,033:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:22,330:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:22,349:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:22,536:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:22,578:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:22,658:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:22,697:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:22,724:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:22,756:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:22,772:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:22,907:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:22,922:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:23,022:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:23,046:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:23,071:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:23,089:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:23,113:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:23,157:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:23,172:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:23,217:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:23,310:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:23,335:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:23,377:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:23,407:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:23,431:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:23,459:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:23,559:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:23,632:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:23,675:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:25,070:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:25,158:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:25,209:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:25,245:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:25,345:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:25,432:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:25,484:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:01:25,517:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:01:25,735:INFO:Calculating mean and std
2025-06-18 02:01:25,737:INFO:Creating metrics dataframe
2025-06-18 02:01:25,741:INFO:Uploading results into container
2025-06-18 02:01:25,742:INFO:Uploading model into container now
2025-06-18 02:01:25,743:INFO:_master_model_container: 4
2025-06-18 02:01:25,743:INFO:_display_container: 2
2025-06-18 02:01:25,744:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-06-18 02:01:25,744:INFO:create_model() successfully completed......................................
2025-06-18 02:01:25,834:INFO:SubProcess create_model() end ==================================
2025-06-18 02:01:25,834:INFO:Creating metrics dataframe
2025-06-18 02:01:25,836:INFO:Initializing SVM - Linear Kernel
2025-06-18 02:01:25,836:INFO:Total runtime is 4.485750464598338 minutes
2025-06-18 02:01:25,836:INFO:SubProcess create_model() called ==================================
2025-06-18 02:01:25,836:INFO:Initializing create_model()
2025-06-18 02:01:25,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x102534e10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e762710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-18 02:01:25,836:INFO:Checking exceptions
2025-06-18 02:01:25,836:INFO:Importing libraries
2025-06-18 02:01:25,836:INFO:Copying training dataset
2025-06-18 02:01:25,883:INFO:Defining folds
2025-06-18 02:01:25,883:INFO:Declaring metric variables
2025-06-18 02:01:25,883:INFO:Importing untrained model
2025-06-18 02:01:25,883:INFO:SVM - Linear Kernel Imported successfully
2025-06-18 02:01:25,883:INFO:Starting cross validation
2025-06-18 02:01:25,886:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-18 02:02:20,101:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:20,160:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:20,354:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:20,436:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:20,490:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:20,531:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:20,665:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:20,830:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:21,311:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:21,365:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:21,545:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:21,649:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:02:21,721:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:22,488:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:22,541:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:22,657:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:22,780:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:22,783:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:22,834:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:22,976:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:23,091:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:23,254:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:23,301:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:23,410:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:23,476:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:02:23,522:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:23,550:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:23,596:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:23,702:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:23,771:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:02:23,826:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:25,928:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:26,029:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:26,259:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:26,495:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:35,039:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:35,072:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:35,152:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:35,166:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:35,198:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:02:35,199:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:35,231:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:35,277:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:35,323:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:02:35,356:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:35,576:INFO:Calculating mean and std
2025-06-18 02:02:35,577:INFO:Creating metrics dataframe
2025-06-18 02:02:35,581:INFO:Uploading results into container
2025-06-18 02:02:35,581:INFO:Uploading model into container now
2025-06-18 02:02:35,582:INFO:_master_model_container: 5
2025-06-18 02:02:35,582:INFO:_display_container: 2
2025-06-18 02:02:35,583:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-18 02:02:35,583:INFO:create_model() successfully completed......................................
2025-06-18 02:02:35,707:INFO:SubProcess create_model() end ==================================
2025-06-18 02:02:35,708:INFO:Creating metrics dataframe
2025-06-18 02:02:35,709:INFO:Initializing Ridge Classifier
2025-06-18 02:02:35,709:INFO:Total runtime is 5.650310802459717 minutes
2025-06-18 02:02:35,709:INFO:SubProcess create_model() called ==================================
2025-06-18 02:02:35,710:INFO:Initializing create_model()
2025-06-18 02:02:35,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x102534e10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e762710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-18 02:02:35,710:INFO:Checking exceptions
2025-06-18 02:02:35,710:INFO:Importing libraries
2025-06-18 02:02:35,710:INFO:Copying training dataset
2025-06-18 02:02:35,755:INFO:Defining folds
2025-06-18 02:02:35,756:INFO:Declaring metric variables
2025-06-18 02:02:35,756:INFO:Importing untrained model
2025-06-18 02:02:35,756:INFO:Ridge Classifier Imported successfully
2025-06-18 02:02:35,756:INFO:Starting cross validation
2025-06-18 02:02:35,758:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-18 02:02:40,070:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:40,131:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:40,273:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:40,290:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:40,338:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:40,392:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:02:40,451:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:40,476:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:40,565:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:02:40,588:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:40,631:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:40,639:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:40,699:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:40,761:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:40,783:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:40,868:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:02:40,908:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:40,916:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:40,923:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:40,959:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:40,971:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:40,991:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:02:41,035:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:41,071:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:41,119:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:41,166:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:41,200:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:02:41,248:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:02:41,259:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:41,301:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:41,342:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:41,385:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:41,491:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:41,506:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:41,553:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:41,558:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:02:41,613:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:41,678:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:41,742:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:02:41,786:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:42,895:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:42,928:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:42,998:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:02:43,007:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:43,030:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:43,053:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:02:43,085:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:43,109:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:43,155:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:02:43,187:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:02:43,395:INFO:Calculating mean and std
2025-06-18 02:02:43,396:INFO:Creating metrics dataframe
2025-06-18 02:02:43,400:INFO:Uploading results into container
2025-06-18 02:02:43,400:INFO:Uploading model into container now
2025-06-18 02:02:43,401:INFO:_master_model_container: 6
2025-06-18 02:02:43,401:INFO:_display_container: 2
2025-06-18 02:02:43,401:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-06-18 02:02:43,402:INFO:create_model() successfully completed......................................
2025-06-18 02:02:43,500:INFO:SubProcess create_model() end ==================================
2025-06-18 02:02:43,500:INFO:Creating metrics dataframe
2025-06-18 02:02:43,502:INFO:Initializing Random Forest Classifier
2025-06-18 02:02:43,502:INFO:Total runtime is 5.78019151687622 minutes
2025-06-18 02:02:43,502:INFO:SubProcess create_model() called ==================================
2025-06-18 02:02:43,502:INFO:Initializing create_model()
2025-06-18 02:02:43,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x102534e10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e762710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-18 02:02:43,502:INFO:Checking exceptions
2025-06-18 02:02:43,502:INFO:Importing libraries
2025-06-18 02:02:43,503:INFO:Copying training dataset
2025-06-18 02:02:43,549:INFO:Defining folds
2025-06-18 02:02:43,549:INFO:Declaring metric variables
2025-06-18 02:02:43,549:INFO:Importing untrained model
2025-06-18 02:02:43,549:INFO:Random Forest Classifier Imported successfully
2025-06-18 02:02:43,549:INFO:Starting cross validation
2025-06-18 02:02:43,551:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-18 02:03:20,822:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:21,880:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:22,316:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:22,430:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:22,582:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:23,027:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:23,453:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:23,657:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:23,707:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:24,397:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:24,572:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:24,647:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:24,656:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:24,725:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:24,728:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:24,793:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:24,805:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:24,882:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:24,890:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:24,898:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:24,945:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:24,948:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:24,959:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:25,011:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:25,396:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:25,411:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:25,519:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:25,533:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:25,608:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:25,640:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:25,653:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:34,179:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:34,184:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:34,270:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:34,275:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:34,323:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:34,329:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:34,357:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:34,362:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:34,576:INFO:Calculating mean and std
2025-06-18 02:03:34,577:INFO:Creating metrics dataframe
2025-06-18 02:03:34,581:INFO:Uploading results into container
2025-06-18 02:03:34,582:INFO:Uploading model into container now
2025-06-18 02:03:34,583:INFO:_master_model_container: 7
2025-06-18 02:03:34,583:INFO:_display_container: 2
2025-06-18 02:03:34,584:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-06-18 02:03:34,584:INFO:create_model() successfully completed......................................
2025-06-18 02:03:34,682:INFO:SubProcess create_model() end ==================================
2025-06-18 02:03:34,683:INFO:Creating metrics dataframe
2025-06-18 02:03:34,684:INFO:Initializing Quadratic Discriminant Analysis
2025-06-18 02:03:34,684:INFO:Total runtime is 6.633226597309112 minutes
2025-06-18 02:03:34,684:INFO:SubProcess create_model() called ==================================
2025-06-18 02:03:34,685:INFO:Initializing create_model()
2025-06-18 02:03:34,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x102534e10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e762710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-18 02:03:34,685:INFO:Checking exceptions
2025-06-18 02:03:34,685:INFO:Importing libraries
2025-06-18 02:03:34,685:INFO:Copying training dataset
2025-06-18 02:03:34,731:INFO:Defining folds
2025-06-18 02:03:34,731:INFO:Declaring metric variables
2025-06-18 02:03:34,732:INFO:Importing untrained model
2025-06-18 02:03:34,732:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-18 02:03:34,732:INFO:Starting cross validation
2025-06-18 02:03:34,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-18 02:03:39,496:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-18 02:03:39,558:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-18 02:03:40,048:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-18 02:03:40,653:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-18 02:03:40,764:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-18 02:03:41,042:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-18 02:03:41,487:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:03:41,567:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:41,579:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:03:41,691:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:41,745:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:41,853:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:41,864:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:41,925:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:41,958:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:03:41,994:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:42,051:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:42,085:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:42,139:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-18 02:03:42,163:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-18 02:03:42,221:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:42,321:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:42,381:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:42,393:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:03:42,449:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:42,565:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:03:42,601:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:03:42,609:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:42,640:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:42,675:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:42,709:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:42,760:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:42,793:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:42,858:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:42,859:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:42,903:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:42,951:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:42,997:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:43,156:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:03:43,159:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:03:43,201:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:43,204:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:43,319:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:43,326:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:43,380:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:43,387:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:43,423:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:43,430:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:44,790:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-18 02:03:44,842:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-18 02:03:45,138:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:03:45,171:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:45,185:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:03:45,217:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:45,248:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:45,293:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:45,294:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:45,325:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:45,340:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:03:45,372:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:03:45,581:INFO:Calculating mean and std
2025-06-18 02:03:45,582:INFO:Creating metrics dataframe
2025-06-18 02:03:45,586:INFO:Uploading results into container
2025-06-18 02:03:45,587:INFO:Uploading model into container now
2025-06-18 02:03:45,587:INFO:_master_model_container: 8
2025-06-18 02:03:45,587:INFO:_display_container: 2
2025-06-18 02:03:45,588:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-18 02:03:45,588:INFO:create_model() successfully completed......................................
2025-06-18 02:03:45,685:INFO:SubProcess create_model() end ==================================
2025-06-18 02:03:45,685:INFO:Creating metrics dataframe
2025-06-18 02:03:45,687:INFO:Initializing Ada Boost Classifier
2025-06-18 02:03:45,687:INFO:Total runtime is 6.816603751977285 minutes
2025-06-18 02:03:45,687:INFO:SubProcess create_model() called ==================================
2025-06-18 02:03:45,687:INFO:Initializing create_model()
2025-06-18 02:03:45,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x102534e10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e762710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-18 02:03:45,687:INFO:Checking exceptions
2025-06-18 02:03:45,687:INFO:Importing libraries
2025-06-18 02:03:45,687:INFO:Copying training dataset
2025-06-18 02:03:45,732:INFO:Defining folds
2025-06-18 02:03:45,732:INFO:Declaring metric variables
2025-06-18 02:03:45,732:INFO:Importing untrained model
2025-06-18 02:03:45,733:INFO:Ada Boost Classifier Imported successfully
2025-06-18 02:03:45,733:INFO:Starting cross validation
2025-06-18 02:03:45,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-18 02:03:50,098:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-18 02:03:50,595:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-18 02:03:50,685:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-18 02:03:50,817:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-18 02:03:50,965:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-18 02:03:51,666:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-18 02:03:52,556:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-18 02:03:52,837:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-18 02:04:09,969:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:04:10,046:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:10,255:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:10,379:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:04:10,445:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:10,980:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:04:11,064:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:04:11,074:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:11,151:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:11,203:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:04:11,241:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:11,266:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:04:11,273:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:11,329:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:11,330:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:04:11,335:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:04:11,351:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:11,385:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:11,415:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:11,528:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:04:11,556:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:11,598:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:11,609:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:11,629:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:11,670:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:04:11,712:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:04:11,741:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:11,746:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:04:11,779:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:11,815:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:12,167:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:04:12,175:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:04:12,218:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:12,227:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:12,330:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:12,342:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:12,391:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:04:12,404:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:04:12,437:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:12,451:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:13,278:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-18 02:04:13,521:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-18 02:04:20,147:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:04:20,179:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:20,258:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:20,303:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:04:20,334:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:20,395:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-18 02:04:20,428:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:20,505:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:20,549:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-18 02:04:20,580:WARNING:/Users/om/Documents/Github-Projects/shadowpersona/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'status-driven') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-06-18 02:04:20,794:INFO:Calculating mean and std
2025-06-18 02:04:20,796:INFO:Creating metrics dataframe
2025-06-18 02:04:20,800:INFO:Uploading results into container
2025-06-18 02:04:20,801:INFO:Uploading model into container now
2025-06-18 02:04:20,801:INFO:_master_model_container: 9
2025-06-18 02:04:20,801:INFO:_display_container: 2
2025-06-18 02:04:20,802:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-06-18 02:04:20,802:INFO:create_model() successfully completed......................................
2025-06-18 02:04:20,889:INFO:SubProcess create_model() end ==================================
2025-06-18 02:04:20,889:INFO:Creating metrics dataframe
2025-06-18 02:04:20,891:INFO:Initializing Gradient Boosting Classifier
2025-06-18 02:04:20,891:INFO:Total runtime is 7.403339417775472 minutes
2025-06-18 02:04:20,891:INFO:SubProcess create_model() called ==================================
2025-06-18 02:04:20,891:INFO:Initializing create_model()
2025-06-18 02:04:20,891:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x102534e10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e762710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-18 02:04:20,891:INFO:Checking exceptions
2025-06-18 02:04:20,891:INFO:Importing libraries
2025-06-18 02:04:20,891:INFO:Copying training dataset
2025-06-18 02:04:20,936:INFO:Defining folds
2025-06-18 02:04:20,936:INFO:Declaring metric variables
2025-06-18 02:04:20,936:INFO:Importing untrained model
2025-06-18 02:04:20,937:INFO:Gradient Boosting Classifier Imported successfully
2025-06-18 02:04:20,937:INFO:Starting cross validation
2025-06-18 02:04:20,939:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
